{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"facebook/wav2vec2-base-960h\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_attn_dim\": null,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "torch.Size([2310, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1774080 and 768x1536)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 50\u001B[0m\n\u001B[0;32m     48\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m#print(test_input_waveform.shape)\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_input_waveform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Print or use the output as needed\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel Output Shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, output\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[12], line 28\u001B[0m, in \u001B[0;36mSpeakerSeparationModel.forward\u001B[1;34m(self, input_waveform, labels)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(wav2vec2_output\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwav2vec2\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Learnable clustering head forward pass\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m clustering_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclustering_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav2vec2_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# Learnable linear layer for conversion\u001B[39;00m\n\u001B[0;32m     31\u001B[0m conversion_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_conversion(clustering_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x1774080 and 768x1536)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Wav2Vec2Model\n",
    "\n",
    "class SpeakerSeparationModel(nn.Module):\n",
    "    def __init__(self, num_speakers):\n",
    "        super(SpeakerSeparationModel, self).__init__()\n",
    "        \n",
    "        # Frozen Wav2Vec2 base\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        for param in self.wav2vec2.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Learnable clustering head\n",
    "        self.clustering_head = nn.Linear(self.wav2vec2.config.hidden_size, num_speakers * self.wav2vec2.config.hidden_size)\n",
    "        \n",
    "        # Learnable linear layer for conversion\n",
    "        self.linear_conversion = nn.Linear(self.wav2vec2.config.hidden_size * num_speakers, 2 * self.wav2vec2.config.hidden_size)\n",
    "        \n",
    "    def forward(self, input_waveform, labels=None):\n",
    "        # Wav2Vec2 forward pass\n",
    "        #print(input_waveform.flatten(1).shape)\n",
    "        print(self.wav2vec2.config)\n",
    "        wav2vec2_output = self.wav2vec2(input_waveform.flatten(1)).last_hidden_state\n",
    "        print(wav2vec2_output.reshape(-1,self.wav2vec2.config.hidden_size).shape)\n",
    "        # Learnable clustering head forward pass\n",
    "        clustering_output = self.clustering_head(wav2vec2_output.flatten(1))\n",
    "        \n",
    "        # Learnable linear layer for conversion\n",
    "        conversion_output = self.linear_conversion(clustering_output)\n",
    "        \n",
    "        # Determine the size based on the input waveform size\n",
    "        batch_size, _, amplitude = input_waveform.size()\n",
    "        conversion_output = conversion_output.view(batch_size, 2, -1)\n",
    "        \n",
    "        return conversion_output\n",
    "\n",
    "# Define your test input waveform\n",
    "test_input_waveform = torch.randn(1, 1, 739440)  # Adjusted to the provided amplitude value\n",
    "\n",
    "# Initialize the SpeakerSeparationModel\n",
    "num_speakers = 2\n",
    "model = SpeakerSeparationModel(num_speakers)\n",
    "\n",
    "# Forward pass to get the output\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    #print(test_input_waveform.shape)\n",
    "    output = model(test_input_waveform)\n",
    "\n",
    "# Print or use the output as needed\n",
    "print(\"Model Output Shape:\", output.shape)\n",
    "print(\"Model Output:\", output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T15:13:46.890499700Z",
     "start_time": "2023-12-04T15:13:35.841023300Z"
    }
   },
   "id": "298295aacefa5ce0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c65f9bc9b3745b2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2288, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1757184 and 768x1536)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     12\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()  \u001B[38;5;66;03m# Set the model to evaluation mode\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_input_waveform\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Print or use the output as needed\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel Output Shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, output\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[20], line 27\u001B[0m, in \u001B[0;36mSpeakerSeparationModel.forward\u001B[1;34m(self, input_waveform, labels)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Learnable clustering head forward pass\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(wav2vec2_output\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m---> 27\u001B[0m clustering_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclustering_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav2vec2_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Learnable linear layer for conversion\u001B[39;00m\n\u001B[0;32m     30\u001B[0m conversion_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_conversion(wav2vec2_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x1757184 and 768x1536)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define your test input waveform\n",
    "test_input_waveform = torch.randn(1, 732440)  # Replace 'amplitude' with the actual size of your input waveform\n",
    "\n",
    "# Initialize the SpeakerSeparationModel\n",
    "num_speakers = 2  # Adjust as per your requirement\n",
    "model = SpeakerSeparationModel(num_speakers)\n",
    "\n",
    "# Forward pass to get the output\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    output = model(test_input_waveform).logits\n",
    "\n",
    "# Print or use the output as needed\n",
    "print(\"Model Output Shape:\", output.shape)\n",
    "print(\"Model Output:\", output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T14:39:28.169480Z",
     "start_time": "2023-12-04T14:39:17.702660Z"
    }
   },
   "id": "e7049ec8a10de6cf"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1774080 and 768x1536)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 43\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     42\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m---> 43\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_input_waveform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Print or use the output as needed\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel Output Shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, output\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[3], line 26\u001B[0m, in \u001B[0;36mSpeakerSeparationModel.forward\u001B[1;34m(self, input_waveform, labels)\u001B[0m\n\u001B[0;32m     23\u001B[0m wav2vec2_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwav2vec2(input_waveform)\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Learnable clustering head forward pass\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m clustering_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclustering_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav2vec2_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Learnable linear layer for conversion\u001B[39;00m\n\u001B[0;32m     29\u001B[0m conversion_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_conversion(clustering_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x1774080 and 768x1536)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Wav2Vec2Model\n",
    "\n",
    "class SpeakerSeparationModel(nn.Module):\n",
    "    def __init__(self, num_speakers):\n",
    "        super(SpeakerSeparationModel, self).__init__()\n",
    "        \n",
    "        # Frozen Wav2Vec2 base\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        for param in self.wav2vec2.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Learnable clustering head\n",
    "        self.clustering_head = nn.Linear(self.wav2vec2.config.hidden_size, num_speakers * self.wav2vec2.config.hidden_size)\n",
    "        \n",
    "        # Learnable linear layer for conversion\n",
    "        self.linear_conversion = nn.Linear(self.wav2vec2.config.hidden_size * num_speakers, 2 * 739440)  # Adjusted the output size\n",
    "        \n",
    "    def forward(self, input_waveform, labels=None):\n",
    "        # Wav2Vec2 forward pass\n",
    "        wav2vec2_output = self.wav2vec2(input_waveform).last_hidden_state\n",
    "        \n",
    "        # Learnable clustering head forward pass\n",
    "        clustering_output = self.clustering_head(wav2vec2_output.flatten(1))\n",
    "        \n",
    "        # Learnable linear layer for conversion\n",
    "        conversion_output = self.linear_conversion(clustering_output)\n",
    "        \n",
    "        return conversion_output.view(conversion_output.size(0), 2, -1)\n",
    "\n",
    "# Define your test input waveform\n",
    "test_input_waveform = torch.randn(1, 739440)  # Adjusted to the provided amplitude value\n",
    "\n",
    "# Initialize the SpeakerSeparationModel\n",
    "num_speakers = 2\n",
    "model = SpeakerSeparationModel(num_speakers)\n",
    "\n",
    "# Forward pass to get the output\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(test_input_waveform)\n",
    "\n",
    "# Print or use the output as needed\n",
    "print(\"Model Output Shape:\", output.shape)\n",
    "print(\"Model Output:\", output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T14:21:47.804909800Z",
     "start_time": "2023-12-04T14:21:12.856396600Z"
    }
   },
   "id": "c42554509d765dc1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utils import LibriMixDataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:02:44.347357900Z",
     "start_time": "2023-12-04T20:02:38.871734300Z"
    }
   },
   "id": "5508324cd758bb0f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_set, val_set = LibriMixDataset(dev_mode=True).load_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:03:00.593344100Z",
     "start_time": "2023-12-04T20:02:44.347357900Z"
    }
   },
   "id": "247f1b7ef0c341d8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_set = train_set[:50]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:03:00.649806200Z",
     "start_time": "2023-12-04T20:03:00.593344100Z"
    }
   },
   "id": "1396a3b86a55f778"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Extract individual components from the batch\n",
    "    sampling_rates, mixture_waveforms, source_waveforms = zip(*batch)\n",
    "\n",
    "    # Find the maximum length of the mixture waveforms\n",
    "    max_mixture_length = max(waveform.shape[1] for waveform in mixture_waveforms)\n",
    "\n",
    "    # Pad the mixture waveforms\n",
    "    padded_mixture_waveforms = torch.stack([\n",
    "        pad(waveform, (0, max_mixture_length - waveform.shape[1]))\n",
    "        for waveform in mixture_waveforms\n",
    "    ], dim=0)\n",
    "\n",
    "    # Find the maximum length of the source waveforms\n",
    "    max_source_length = max(waveform.shape[1] for sources in source_waveforms for waveform in sources)\n",
    "\n",
    "    # Pad the source waveforms\n",
    "    padded_source_waveforms = [\n",
    "        torch.stack([\n",
    "            pad(waveform, (0, max_source_length - waveform.shape[1]))\n",
    "            for waveform in sources\n",
    "        ], dim=0)\n",
    "        for sources in zip(*source_waveforms)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'sampling_rates': torch.tensor(sampling_rates),\n",
    "        'mixture_waveforms': padded_mixture_waveforms,\n",
    "        'source_waveforms': padded_source_waveforms\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:04:15.887064100Z",
     "start_time": "2023-12-04T20:04:15.853962200Z"
    }
   },
   "id": "6637690bc28c798c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.8841861514084979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.1304139086878573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.957213070242158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9972164057668402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.673601191245301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.2540621151713216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.1532665411080414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.033016617614487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6042092260071863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.002386957602284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.025419158815022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0769028906545364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6487446779067327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.2284031357579432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.362570733268618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.1649815384555926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6610434586848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.066244998540154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.427523544529071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.1373325010823296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9695740500542651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.7898962961464486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0540036791458447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.727996624755283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9534841604135211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9627702972969496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.105448369663089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6783404589334094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0317423824601772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6644290903638639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.714347835889536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.689802184561159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0901984923773473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0488413232698086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.7382955578312504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6006383155446324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.912459469291889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.7443255349787268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.1781716683580097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.918638416648557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.6129266106472948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9782071936413521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.09516206726749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.0023234450111573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.125011294937841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.9435809798073393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.221077070644436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.674527619585569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 1.8888159301456398\n",
      "Davies-Bouldin Index: 2.124545250811051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Define Wav2Vec 2.0 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Freeze the parameters of the Wav2Vec 2.0 model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define your clustering model\n",
    "num_clusters = 2  # Use the number of source waveforms as clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "\n",
    "# Define your training data\n",
    "# Replace this with your actual training data loading logic\n",
    "sampling_rate = 16000  # Adjust based on your data\n",
    "#train_set = [(sampling_rate, mix_waveform, source_waveforms)]\n",
    "\n",
    "# Feature extraction and clustering\n",
    "for _, mix_waveform, source_waveforms in train_set:\n",
    "    # Feature extraction using Wav2Vec 2.0\n",
    "    mix_input_values = processor(mix_waveform, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000).input_values\n",
    "    mix_input_values = mix_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "    mix_outputs = model(mix_input_values.unsqueeze(0))  # Add batch dimension\n",
    "    mix_logits = mix_outputs.logits.squeeze()\n",
    "    #print(mix_logits.shape)\n",
    "\n",
    "    source_features_list = []\n",
    "    for source_waveform in source_waveforms:\n",
    "        source_input_values = processor(source_waveform, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000).input_values\n",
    "        source_input_values = source_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "        source_outputs = model(source_input_values.unsqueeze(0))  # Add batch dimension\n",
    "        source_logits = source_outputs.logits.squeeze()\n",
    "        source_features_list.append(source_logits)\n",
    "        #print(len(source_features_list))\n",
    "\n",
    "    # Convert features to numpy arrays\n",
    "    mix_features_np = mix_logits.detach().numpy()\n",
    "    #print(mix_features_np.shape)\n",
    "    source_features_np = torch.cat(source_features_list).detach().numpy()\n",
    "    #print(source_features_np.shape)\n",
    "    # Apply KMeans clustering to mix features\n",
    "    mix_cluster_labels = kmeans.fit_predict(mix_features_np)\n",
    "\n",
    "    # Separate mix waveform based on cluster labels\n",
    "    \n",
    "    from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "    davies_bouldin = davies_bouldin_score(mix_features_np, mix_cluster_labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "\n",
    "    # Apply KMeans clustering to source features\n",
    "    # Extract cluster information\n",
    "    # cluster_centers = torch.tensor(kmeans.cluster_centers_)  # Centroids of clusters\n",
    "    # cluster_labels = torch.tensor(mix_cluster_labels)  # Labels assigned to each point\n",
    "    # \n",
    "    # # Example: Access the cluster information for the first cluster\n",
    "    # cluster_center = cluster_centers[0]\n",
    "    # cluster_points = mix_logits[cluster_labels == 0]\n",
    "    # Separate mix waveform based on cluster labels\n",
    "    # separated_waveforms = []\n",
    "    # for cluster_label in range(num_clusters):\n",
    "    #     cluster_indices = torch.nonzero(cluster_label == mix_cluster_labels)\n",
    "    #     cluster_waveform = mix_waveform[:, cluster_indices].mean(dim=1)  # You can use mean or any other aggregation method\n",
    "    #     separated_waveforms.append(cluster_waveform)\n",
    "\n",
    "    # 'separated_waveforms' now contains individual source waveforms\n",
    "\n",
    "# You can further process or save the separated_waveforms as needed\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T21:34:07.853795700Z",
     "start_time": "2023-12-04T21:32:41.025169100Z"
    }
   },
   "id": "1534c80cb64f7656"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9fea5c1d3d460371"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Kedar Pandya\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 49\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Apply KMeans clustering to mix features\u001B[39;00m\n\u001B[0;32m     48\u001B[0m mix_cluster_labels_k \u001B[38;5;241m=\u001B[39m kmeans\u001B[38;5;241m.\u001B[39mfit_predict(mix_features_np)\n\u001B[1;32m---> 49\u001B[0m mix_cluster_labels_s \u001B[38;5;241m=\u001B[39m \u001B[43mspectral_clustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmix_features_np\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Separate mix waveform based on cluster labels\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Calculate Davies-Bouldin Index\u001B[39;00m\n\u001B[0;32m     53\u001B[0m davies_bouldin_k \u001B[38;5;241m=\u001B[39m davies_bouldin_score(mix_features_np, mix_cluster_labels_k)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:778\u001B[0m, in \u001B[0;36mSpectralClustering.fit_predict\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    757\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Perform spectral clustering on `X` and return cluster labels.\u001B[39;00m\n\u001B[0;32m    758\u001B[0m \n\u001B[0;32m    759\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    776\u001B[0m \u001B[38;5;124;03m        Cluster labels.\u001B[39;00m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\base.py:791\u001B[0m, in \u001B[0;36mClusterMixin.fit_predict\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    774\u001B[0m \u001B[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001B[39;00m\n\u001B[0;32m    775\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;124;03m    Cluster labels.\u001B[39;00m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    789\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    790\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[1;32m--> 791\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels_\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\cluster\\_spectral.py:730\u001B[0m, in \u001B[0;36mSpectralClustering.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    721\u001B[0m n_components \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_clusters \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components\n\u001B[0;32m    723\u001B[0m )\n\u001B[0;32m    724\u001B[0m \u001B[38;5;66;03m# We now obtain the real valued solution matrix to the\u001B[39;00m\n\u001B[0;32m    725\u001B[0m \u001B[38;5;66;03m# relaxed Ncut problem, solving the eigenvalue problem\u001B[39;00m\n\u001B[0;32m    726\u001B[0m \u001B[38;5;66;03m# L_sym x = lambda x  and recovering u = D^-1/2 x.\u001B[39;00m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;66;03m# The first eigenvector is constant only for fully connected graphs\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;66;03m# and should be kept for spectral clustering (drop_first = False)\u001B[39;00m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;66;03m# See spectral_embedding documentation.\u001B[39;00m\n\u001B[1;32m--> 730\u001B[0m maps \u001B[38;5;241m=\u001B[39m \u001B[43mspectral_embedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    731\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maffinity_matrix_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    732\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_components\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_components\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[43m    \u001B[49m\u001B[43meigen_solver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meigen_solver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    734\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[43m    \u001B[49m\u001B[43meigen_tol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meigen_tol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdrop_first\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    737\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputing label assignment using \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massign_labels\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:313\u001B[0m, in \u001B[0;36mspectral_embedding\u001B[1;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first)\u001B[0m\n\u001B[0;32m    311\u001B[0m laplacian \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    312\u001B[0m v0 \u001B[38;5;241m=\u001B[39m _init_arpack_v0(laplacian\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], random_state)\n\u001B[1;32m--> 313\u001B[0m _, diffusion_map \u001B[38;5;241m=\u001B[39m \u001B[43meigsh\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlaplacian\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLM\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mv0\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m embedding \u001B[38;5;241m=\u001B[39m diffusion_map\u001B[38;5;241m.\u001B[39mT[n_components::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m norm_laplacian:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;66;03m# recover u = D^-1/2 x from the eigenvector output x\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\arpack\\arpack.py:1697\u001B[0m, in \u001B[0;36meigsh\u001B[1;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001B[0m\n\u001B[0;32m   1695\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _ARPACK_LOCK:\n\u001B[0;32m   1696\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m params\u001B[38;5;241m.\u001B[39mconverged:\n\u001B[1;32m-> 1697\u001B[0m         \u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1699\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m params\u001B[38;5;241m.\u001B[39mextract(return_eigenvectors)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\arpack\\arpack.py:560\u001B[0m, in \u001B[0;36m_SymmetricArpackParams.iterate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    558\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    559\u001B[0m         Bxslice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mslice\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipntr[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipntr[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn)\n\u001B[1;32m--> 560\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkd[yslice] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOPa\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworkd\u001B[49m\u001B[43m[\u001B[49m\u001B[43mBxslice\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    561\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mido \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkd[yslice] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mB(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkd[xslice])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py:234\u001B[0m, in \u001B[0;36mLinearOperator.matvec\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,) \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension mismatch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 234\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_matvec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mmatrix):\n\u001B[0;32m    237\u001B[0m     y \u001B[38;5;241m=\u001B[39m asmatrix(y)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\arpack\\arpack.py:944\u001B[0m, in \u001B[0;36mLuInv._matvec\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    943\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_matvec\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 944\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlu_solve\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mM_lu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\scipy\\linalg\\_decomp_lu.py:152\u001B[0m, in \u001B[0;36mlu_solve\u001B[1;34m(lu_and_piv, b, trans, overwrite_b, check_finite)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShapes of lu \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and b \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m are incompatible\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    149\u001B[0m                      \u001B[38;5;241m.\u001B[39mformat(lu\u001B[38;5;241m.\u001B[39mshape, b1\u001B[38;5;241m.\u001B[39mshape))\n\u001B[0;32m    151\u001B[0m getrs, \u001B[38;5;241m=\u001B[39m get_lapack_funcs((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgetrs\u001B[39m\u001B[38;5;124m'\u001B[39m,), (lu, b1))\n\u001B[1;32m--> 152\u001B[0m x, info \u001B[38;5;241m=\u001B[39m \u001B[43mgetrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpiv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverwrite_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverwrite_b\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Define Wav2Vec 2.0 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Freeze the parameters of the Wav2Vec 2.0 model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define your clustering model\n",
    "num_clusters = 2  # Use the number of source waveforms as clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "#dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "spectral_clustering = SpectralClustering(n_clusters=num_clusters, random_state=0)\n",
    "\n",
    "# Define your training data\n",
    "# Replace this with your actual training data loading logic\n",
    "sampling_rate = 16000  # Adjust based on your data\n",
    "\n",
    "# Feature extraction and clustering\n",
    "mix_features_list = []\n",
    "source_features_list = []\n",
    "\n",
    "for _, mix_waveform, source_waveforms in train_set:\n",
    "    # Feature extraction using Wav2Vec 2.0 for mix waveform\n",
    "    mix_input_values = processor(mix_waveform, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000).input_values.squeeze()\n",
    "    mix_outputs = model(mix_input_values.unsqueeze(0))\n",
    "    mix_logits = mix_outputs.logits.squeeze()\n",
    "    mix_features_list.append(mix_logits.detach())\n",
    "\n",
    "    # Feature extraction using Wav2Vec 2.0 for each source waveform\n",
    "    for source_waveform in source_waveforms:\n",
    "        source_input_values = processor(source_waveform, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000).input_values.squeeze()\n",
    "        source_outputs = model(source_input_values.unsqueeze(0))\n",
    "        source_logits = source_outputs.logits.squeeze()\n",
    "        source_features_list.append(source_logits.detach())\n",
    "\n",
    "# Convert features to numpy arrays\n",
    "mix_features_np = torch.cat(mix_features_list).detach().numpy()\n",
    "source_features_np = torch.cat(source_features_list).detach().numpy()\n",
    "\n",
    "# Apply KMeans clustering to mix features\n",
    "mix_cluster_labels_k = kmeans.fit_predict(mix_features_np)\n",
    "mix_cluster_labels_s = spectral_clustering.fit_predict(mix_features_np)\n",
    "# Separate mix waveform based on cluster labels\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "davies_bouldin_k = davies_bouldin_score(mix_features_np, mix_cluster_labels_k)\n",
    "davies_bouldin_s = davies_bouldin_score(mix_features_np, mix_cluster_labels_s)\n",
    "print(f\"Davies-Bouldin Index for K-Means: {davies_bouldin_k}\")\n",
    "print(f\"Davies-Bouldin Index for Spectral Clustering: {davies_bouldin_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T12:44:10.084281100Z",
     "start_time": "2023-12-05T01:14:12.282956100Z"
    }
   },
   "id": "5267e1f1d15d33b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "960f924b8aca6200"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228,)\n"
     ]
    }
   ],
   "source": [
    "rint(mix_cluster_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T17:17:56.341675100Z",
     "start_time": "2023-12-04T17:17:56.304149800Z"
    }
   },
   "id": "4b4e49eef3e5fd81"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn= custom_collate_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T19:52:00.185770500Z",
     "start_time": "2023-12-04T19:52:00.169980500Z"
    }
   },
   "id": "e5ff3edda317176c"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "type of mixture_waveforms unknown: <class 'str'>. Should be one of a python, numpy, pytorch or tensorflow object.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m sampling_rate, mix_waveforms, source_waveforms_list \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Feature extraction using Wav2Vec 2.0\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m mix_input_values \u001B[38;5;241m=\u001B[39m \u001B[43mprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmix_waveforms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlongest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39minput_values\n\u001B[0;32m     37\u001B[0m mix_input_values \u001B[38;5;241m=\u001B[39m mix_input_values\u001B[38;5;241m.\u001B[39msqueeze()  \u001B[38;5;66;03m# Remove unnecessary dimensions\u001B[39;00m\n\u001B[0;32m     38\u001B[0m mix_outputs \u001B[38;5;241m=\u001B[39m model(mix_input_values\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))  \u001B[38;5;66;03m# Add batch dimension\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:93\u001B[0m, in \u001B[0;36mWav2Vec2Processor.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m audio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampling_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer(text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:199\u001B[0m, in \u001B[0;36mWav2Vec2FeatureExtractor.__call__\u001B[1;34m(self, raw_speech, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors, sampling_rate, **kwargs)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# convert into correct format for padding\u001B[39;00m\n\u001B[0;32m    197\u001B[0m encoded_inputs \u001B[38;5;241m=\u001B[39m BatchFeature({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_values\u001B[39m\u001B[38;5;124m\"\u001B[39m: raw_speech})\n\u001B[1;32m--> 199\u001B[0m padded_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoded_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;66;03m# convert input values to correct format\u001B[39;00m\n\u001B[0;32m    209\u001B[0m input_values \u001B[38;5;241m=\u001B[39m padded_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_values\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\feature_extraction_sequence_utils.py:169\u001B[0m, in \u001B[0;36mSequenceFeatureExtractor.pad\u001B[1;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001B[0m\n\u001B[0;32m    167\u001B[0m         return_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    170\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_element\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m unknown: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(first_element)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    171\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould be one of a python, numpy, pytorch or tensorflow object.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    172\u001B[0m         )\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m processed_features\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)):\n",
      "\u001B[1;31mValueError\u001B[0m: type of mixture_waveforms unknown: <class 'str'>. Should be one of a python, numpy, pytorch or tensorflow object."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define Wav2Vec 2.0 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Freeze the parameters of the Wav2Vec 2.0 model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define your learnable clustering model\n",
    "class ClusteringModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_clusters):\n",
    "        super(ClusteringModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_clusters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define your DataLoader\n",
    "# Adjust the batch size and collate function based on your requirements\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Feature extraction and clustering\n",
    "for batch in train_loader:\n",
    "    # Unpack the batch\n",
    "    sampling_rate, mix_waveforms, source_waveforms_list = batch\n",
    "\n",
    "    # Feature extraction using Wav2Vec 2.0\n",
    "    mix_input_values = processor(mix_waveforms, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    mix_input_values = mix_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "    mix_outputs = model(mix_input_values.unsqueeze(0))  # Add batch dimension\n",
    "    mix_logits = mix_outputs.logits.squeeze()\n",
    "\n",
    "    source_features_list = []\n",
    "    for source_waveforms in source_waveforms_list:\n",
    "        source_input_values = processor(source_waveforms, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "        source_input_values = source_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "        source_outputs = model(source_input_values.unsqueeze(0))  # Add batch dimension\n",
    "        source_logits = source_outputs.logits.squeeze()\n",
    "        source_features_list.append(source_logits)\n",
    "\n",
    "    # Convert features to PyTorch tensors\n",
    "    mix_features = mix_logits\n",
    "    source_features = torch.cat(source_features_list)\n",
    "\n",
    "    # Define your learnable clustering model\n",
    "    input_dim = mix_features.size(1)\n",
    "    num_clusters = len(source_waveforms)  # Use the number of sources as clusters\n",
    "    clustering_model = ClusteringModel(input_dim, num_clusters)\n",
    "\n",
    "    # Define your loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(clustering_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop with tqdm\n",
    "    num_epochs = 10  # Adjust as needed\n",
    "    with tqdm(total=num_epochs, desc=\"Training Clustering Model\") as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            cluster_assignments = clustering_model(mix_features)\n",
    "\n",
    "            # Assuming you have ground truth cluster labels, replace 'source_labels' accordingly\n",
    "            source_labels = torch.cat([torch.full((source.size(1),), i) for i, source in enumerate(source_features_list)])\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(cluster_assignments, source_labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "    # After training, you can use clustering_model to predict cluster assignments for new data\n",
    "    new_data_features = torch.tensor(val_set[0])\n",
    "    predicted_labels = torch.argmax(clustering_model(new_data_features), dim=1)\n",
    "\n",
    "    # Evaluate clustering performance using adjusted_rand_score and normalized_mutual_info_score\n",
    "    ari_score = adjusted_rand_score(source_labels.numpy(), predicted_labels.numpy())\n",
    "    nmi_score = normalized_mutual_info_score(source_labels.numpy(), predicted_labels.numpy())\n",
    "\n",
    "    print(f\"Adjusted Rand Index: {ari_score}\")\n",
    "    print(f\"Normalized Mutual Information: {nmi_score}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T00:52:05.457310800Z",
     "start_time": "2023-12-05T00:52:03.628532700Z"
    }
   },
   "id": "57a3ec9fb582cb7a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 1, 10], expected input[1, 73040, 1] to have 1 channels, but got 73040 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, mix_waveform, source_waveforms \u001B[38;5;129;01min\u001B[39;00m train_set:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# Feature extraction using Wav2Vec 2.0\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     mix_input_values \u001B[38;5;241m=\u001B[39m processor(mix_waveform, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlongest\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39minput_values\n\u001B[1;32m---> 23\u001B[0m     mix_features \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmix_input_values\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     source_features_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m source_waveform \u001B[38;5;129;01min\u001B[39;00m source_waveforms:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1962\u001B[0m, in \u001B[0;36mWav2Vec2ForCTC.forward\u001B[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001B[0m\n\u001B[0;32m   1952\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1953\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, target_length)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1954\u001B[0m \u001B[38;5;124;03m    Labels for connectionist temporal classification. Note that `target_length` has to be smaller or equal to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1957\u001B[0m \u001B[38;5;124;03m    config.vocab_size - 1]`.\u001B[39;00m\n\u001B[0;32m   1958\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1960\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1962\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwav2vec2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1963\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1965\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1966\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1967\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1968\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1970\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1971\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1547\u001B[0m, in \u001B[0;36mWav2Vec2Model.forward\u001B[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1542\u001B[0m output_hidden_states \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1543\u001B[0m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39moutput_hidden_states\n\u001B[0;32m   1544\u001B[0m )\n\u001B[0;32m   1545\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1547\u001B[0m extract_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1548\u001B[0m extract_features \u001B[38;5;241m=\u001B[39m extract_features\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m   1550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;66;03m# compute reduced attention_mask corresponding to feature vectors\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:459\u001B[0m, in \u001B[0;36mWav2Vec2FeatureEncoder.forward\u001B[1;34m(self, input_values)\u001B[0m\n\u001B[0;32m    454\u001B[0m         hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    455\u001B[0m             conv_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    456\u001B[0m             hidden_states,\n\u001B[0;32m    457\u001B[0m         )\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 459\u001B[0m         hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mconv_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:362\u001B[0m, in \u001B[0;36mWav2Vec2GroupNormConvLayer.forward\u001B[1;34m(self, hidden_states)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states):\n\u001B[1;32m--> 362\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    363\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m    364\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(hidden_states)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    307\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    308\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Given groups=1, weight of size [512, 1, 10], expected input[1, 73040, 1] to have 1 channels, but got 73040 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Define Wav2Vec 2.0 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Define your clustering model\n",
    "num_clusters = len(source_waveforms)  # Use the number of source waveforms as clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "\n",
    "# Define your training data\n",
    "# Replace this with your actual training data loading logic\n",
    "sampling_rate = 16000  # Adjust based on your data\n",
    "#train_set = [(sampling_rate, mix_waveform, source_waveforms)]\n",
    "\n",
    "# Feature extraction and clustering\n",
    "for _, mix_waveform, source_waveforms in train_set:\n",
    "    # Feature extraction using Wav2Vec 2.0\n",
    "    mix_input_values = processor(mix_waveform, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    mix_features = model(mix_input_values.squeeze())\n",
    "\n",
    "    source_features_list = []\n",
    "    for source_waveform in source_waveforms:\n",
    "        source_input_values = processor(source_waveform, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "        source_features = model(source_input_values.squeeze())\n",
    "        source_features_list.append(source_features)\n",
    "\n",
    "    # Convert features to numpy arrays\n",
    "    mix_features_np = mix_features.detach().numpy()\n",
    "    source_features_np = torch.cat(source_features_list).detach().numpy()\n",
    "\n",
    "    # Apply KMeans clustering to mix features\n",
    "    mix_cluster_labels = kmeans.fit_predict(mix_features_np)\n",
    "\n",
    "    # Separate mix waveform based on cluster labels\n",
    "    # separated_waveforms = []\n",
    "    # for cluster_label in range(num_clusters):\n",
    "    #     cluster_indices = (mix_cluster_labels == cluster_label)\n",
    "    #     cluster_waveform = mix_waveform[:, cluster_indices].mean(dim=1)  # You can use mean or any other aggregation method\n",
    "    #     separated_waveforms.append(cluster_waveform)\n",
    "\n",
    "    # 'separated_waveforms' now contains individual source waveforms\n",
    "\n",
    "# You can further process or save the separated_waveforms as needed\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T21:26:48.365935Z",
     "start_time": "2023-12-04T21:26:46.911150500Z"
    }
   },
   "id": "7efe670137a720df"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from utils import LibriMixDataset\n",
    "train_set, val_set = LibriMixDataset(dev_mode=True).load_dataset()\n",
    "train_set = train_set[:50]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T00:24:36.084998400Z",
     "start_time": "2023-12-05T00:24:20.594000300Z"
    }
   },
   "id": "c2de083db20cfa8e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "type of mixture_waveforms unknown: <class 'str'>. Should be one of a python, numpy, pytorch or tensorflow object.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 49\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(mix_waveforms))\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Feature extraction using Wav2Vec 2.0 for the mixture\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m mix_input_values \u001B[38;5;241m=\u001B[39m \u001B[43mprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmix_waveforms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlongest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39minput_values\n\u001B[0;32m     50\u001B[0m mix_input_values \u001B[38;5;241m=\u001B[39m mix_input_values\u001B[38;5;241m.\u001B[39msqueeze()  \u001B[38;5;66;03m# Remove unnecessary dimensions\u001B[39;00m\n\u001B[0;32m     51\u001B[0m mix_outputs \u001B[38;5;241m=\u001B[39m model(mix_input_values\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))  \u001B[38;5;66;03m# Add batch dimension\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:93\u001B[0m, in \u001B[0;36mWav2Vec2Processor.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m audio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampling_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer(text, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py:199\u001B[0m, in \u001B[0;36mWav2Vec2FeatureExtractor.__call__\u001B[1;34m(self, raw_speech, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors, sampling_rate, **kwargs)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# convert into correct format for padding\u001B[39;00m\n\u001B[0;32m    197\u001B[0m encoded_inputs \u001B[38;5;241m=\u001B[39m BatchFeature({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_values\u001B[39m\u001B[38;5;124m\"\u001B[39m: raw_speech})\n\u001B[1;32m--> 199\u001B[0m padded_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoded_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;66;03m# convert input values to correct format\u001B[39;00m\n\u001B[0;32m    209\u001B[0m input_values \u001B[38;5;241m=\u001B[39m padded_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_values\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\friday\\Lib\\site-packages\\transformers\\feature_extraction_sequence_utils.py:169\u001B[0m, in \u001B[0;36mSequenceFeatureExtractor.pad\u001B[1;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001B[0m\n\u001B[0;32m    167\u001B[0m         return_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    170\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_element\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m unknown: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(first_element)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    171\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould be one of a python, numpy, pytorch or tensorflow object.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    172\u001B[0m         )\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m processed_features\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)):\n",
      "\u001B[1;31mValueError\u001B[0m: type of mixture_waveforms unknown: <class 'str'>. Should be one of a python, numpy, pytorch or tensorflow object."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "\n",
    "# Assuming you have a pre-trained Wav2Vec2 model and processor\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Define your source separation model\n",
    "class SourceSeparationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SourceSeparationModel, self).__init__()\n",
    "        # Define your model architecture (e.g., an LSTM-based model)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, mixture_embedding):\n",
    "        # Pass through the LSTM and linear layer\n",
    "        output, _ = self.lstm(mixture_embedding)\n",
    "        separated_waveform = self.linear(output)\n",
    "\n",
    "        return separated_waveform\n",
    "\n",
    "# Instantiate your source separation model\n",
    "wav2vec2_hidden_size = model.config.hidden_size\n",
    "input_size = wav2vec2_hidden_size  # Input is the embedding of the mixture waveform\n",
    "hidden_size = 256# Define the size of the hidden layer in your model\n",
    "output_size = wav2vec2_hidden_size # Define the size of the output waveform\n",
    "separation_model = SourceSeparationModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(separation_model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming your train_loader is already defined\n",
    "num_epochs = 2# Define the number of training epochs\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        # Unpack the batch\n",
    "        sampling_rate, mix_waveforms, source_waveforms_list = batch\n",
    "        print(type(mix_waveforms))\n",
    "        # Feature extraction using Wav2Vec 2.0 for the mixture\n",
    "        mix_input_values = processor(mix_waveforms, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "        mix_input_values = mix_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "        mix_outputs = model(mix_input_values.unsqueeze(0))  # Add batch dimension\n",
    "        mix_logits = mix_outputs.logits.squeeze()\n",
    "\n",
    "        # Feature extraction for each source waveform\n",
    "        source_features_list = []\n",
    "        for source_waveforms in source_waveforms_list:\n",
    "            source_input_values = processor(source_waveforms, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "            source_input_values = source_input_values.squeeze()  # Remove unnecessary dimensions\n",
    "            source_outputs = model(source_input_values.unsqueeze(0))  # Add batch dimension\n",
    "            source_logits = source_outputs.logits.squeeze()\n",
    "            source_features_list.append(source_logits)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        separated_waveforms = separation_model(mix_logits)\n",
    "\n",
    "        # Flatten the source features list for computing the loss\n",
    "        flat_source_features = torch.cat(source_features_list, dim=0)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(separated_waveforms, flat_source_features)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training statistics (optional)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T00:44:04.926144500Z",
     "start_time": "2023-12-05T00:44:03.864455800Z"
    }
   },
   "id": "89bfa132903dd3ff"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002171FD14090>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T00:43:53.156690Z",
     "start_time": "2023-12-05T00:43:53.142734700Z"
    }
   },
   "id": "bd09fc87ac86a50b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b57a76cd48433c56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
